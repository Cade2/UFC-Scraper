{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4da48a5-3540-4972-8d36-29fa02e6a1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import logging\n",
    "from multiprocessing.pool import ThreadPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e126319-3eb8-4bf0-97f4-781904336d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Columns to extract: FIGHTER, HEIGHT, WEIGHT, REACH, STANCE, DOB\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14efd681-d5e8-46a7-b1b2-208c8338f773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_ufcstats(fighter_name):\n",
    "    base_url = \"http://ufcstats.com/statistics/fighters?char=a&page=all\"\n",
    "    fighter_name_query = fighter_name.replace(\" \", \"-\").lower()\n",
    "    search_url = f\"http://ufcstats.com/fighter-details/{fighter_name_query}\"\n",
    "    \n",
    "    for _ in range(3):  # Retry logic\n",
    "        response = requests.get(search_url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            break\n",
    "        time.sleep(2)\n",
    "    else:\n",
    "        logging.warning(f\"Failed to fetch details for {fighter_name} from UFC Stats\")\n",
    "        return {\"FIGHTER\": fighter_name, \"Source\": \"UFC Stats\", \"Error\": \"Failed to fetch details\"}\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    details = {\"FIGHTER\": fighter_name}\n",
    "\n",
    "    try:\n",
    "        details[\"HEIGHT\"] = soup.find(text=\"Height:\").find_next(\"td\").text.strip()\n",
    "        details[\"WEIGHT\"] = soup.find(text=\"Weight:\").find_next(\"td\").text.strip()\n",
    "        details[\"REACH\"] = soup.find(text=\"Reach:\").find_next(\"td\").text.strip()\n",
    "        details[\"STANCE\"] = soup.find(text=\"Stance:\").find_next(\"td\").text.strip()\n",
    "        details[\"DOB\"] = soup.find(text=\"DOB:\").find_next(\"td\").text.strip()\n",
    "    except AttributeError:\n",
    "        details[\"Error\"] = \"Incomplete data\"\n",
    "\n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "598d3a1c-5c2e-4df3-abe1-96202a03a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_mmadecisions(fighter_name):\n",
    "    base_url = \"https://mmadecisions.com/fighter/\"\n",
    "    fighter_name_query = fighter_name.replace(\" \", \"-\").lower()\n",
    "    search_url = f\"{base_url}{fighter_name_query}\"\n",
    "\n",
    "    for _ in range(3):  # Retry logic\n",
    "        response = requests.get(search_url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            break\n",
    "        time.sleep(2)\n",
    "    else:\n",
    "        logging.warning(f\"Failed to fetch details for {fighter_name} from MMA Decisions\")\n",
    "        return {\"FIGHTER\": fighter_name, \"Source\": \"MMA Decisions\", \"Error\": \"Failed to fetch details\"}\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    details = {\"FIGHTER\": fighter_name}\n",
    "\n",
    "    try:\n",
    "        details[\"HEIGHT\"] = soup.find(text=\"Height:\").find_next(\"td\").text.strip()\n",
    "        details[\"WEIGHT\"] = soup.find(text=\"Weight:\").find_next(\"td\").text.strip()\n",
    "        details[\"REACH\"] = soup.find(text=\"Reach:\").find_next(\"td\").text.strip()\n",
    "        details[\"STANCE\"] = soup.find(text=\"Stance:\").find_next(\"td\").text.strip()\n",
    "        details[\"DOB\"] = soup.find(text=\"DOB:\").find_next(\"td\").text.strip()\n",
    "    except AttributeError:\n",
    "        details[\"Error\"] = \"Incomplete data\"\n",
    "\n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7df44964-e54a-4829-ab69-971aa21b036d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_tapology(fighter_name):\n",
    "    base_url = \"https://www.tapology.com/fightcenter/fighters/\"\n",
    "    fighter_name_query = fighter_name.replace(\" \", \"-\").lower()\n",
    "    search_url = f\"{base_url}{fighter_name_query}\"\n",
    "\n",
    "    for _ in range(3):  # Retry logic\n",
    "        response = requests.get(search_url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            break\n",
    "        time.sleep(2)\n",
    "    else:\n",
    "        logging.warning(f\"Failed to fetch details for {fighter_name} from Tapology\")\n",
    "        return {\"FIGHTER\": fighter_name, \"Source\": \"Tapology\", \"Error\": \"Failed to fetch details\"}\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    details = {\"FIGHTER\": fighter_name}\n",
    "\n",
    "    try:\n",
    "        details[\"HEIGHT\"] = soup.find(text=\"Height:\").find_next(\"td\").text.strip()\n",
    "        details[\"WEIGHT\"] = soup.find(text=\"Weight:\").find_next(\"td\").text.strip()\n",
    "        details[\"REACH\"] = soup.find(text=\"Reach:\").find_next(\"td\").text.strip()\n",
    "        details[\"STANCE\"] = soup.find(text=\"Stance:\").find_next(\"td\").text.strip()\n",
    "        details[\"DOB\"] = soup.find(text=\"DOB:\").find_next(\"td\").text.strip()\n",
    "    except AttributeError:\n",
    "        details[\"Error\"] = \"Incomplete data\"\n",
    "\n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae043b98-cbea-4708-a7c0-86b40302cdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_fighter_details(fighter_name):\n",
    "    logging.info(f\"Starting to scrape details for {fighter_name}\")\n",
    "\n",
    "    # Try scraping from UFC Stats first\n",
    "    details = scrape_ufcstats(fighter_name)\n",
    "    if \"Error\" not in details:\n",
    "        logging.info(f\"Successfully scraped details for {fighter_name} from UFC Stats\")\n",
    "        return details\n",
    "\n",
    "    # If UFC Stats fails, try MMA Decisions\n",
    "    details = scrape_mmadecisions(fighter_name)\n",
    "    if \"Error\" not in details:\n",
    "        logging.info(f\"Successfully scraped details for {fighter_name} from MMA Decisions\")\n",
    "        return details\n",
    "\n",
    "    # If MMA Decisions fails, try Tapology\n",
    "    details = scrape_tapology(fighter_name)\n",
    "    if \"Error\" not in details:\n",
    "        logging.info(f\"Successfully scraped details for {fighter_name} from Tapology\")\n",
    "\n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c5b3255-5343-4bd8-9a78-f8ca211eb351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_from_dataset_parallel(dataset_path, threads=4):\n",
    "    # Load dataset of fighter names\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    if 'Name' not in df.columns:\n",
    "        raise ValueError(\"Dataset must contain a 'Name' column\")\n",
    "\n",
    "    fighter_names = df['Name'].tolist()\n",
    "\n",
    "    # Parallel scraping using ThreadPool\n",
    "    with ThreadPool(threads) as pool:\n",
    "        results = pool.map(scrape_fighter_details, fighter_names)\n",
    "\n",
    "    # Save results to a DataFrame and CSV\n",
    "    result_df = pd.DataFrame(results)\n",
    "    result_df.to_csv(\"scraped_fighter_details.csv\", index=False)\n",
    "    logging.info(\"Scraping complete. Data saved to scraped_fighter_details.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59e341a-4ff7-4d5a-bc7b-1473e79cc5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# Uncomment the line below to scrape a dataset of names in parallel\n",
    "# scrape_from_dataset_parallel(\"fighter_names.csv\", threads=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
